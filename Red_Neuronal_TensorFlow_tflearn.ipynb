{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Red_Neuronal_TensorFlow_tflearn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNgxlyC9d4zjGxYWW9ij2A+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EddyGiusepe/Red_Neuronal_TensorFlow_tflearn/blob/main/Red_Neuronal_TensorFlow_tflearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Jy8NEra9V5r"
      },
      "source": [
        "# Ejemplo de cómo hacer una Red Neuronal en menos de $10$ líneas com ``Tensorflow`` y ``tflearn``\r\n",
        "\r\n",
        "Este ejemplo puede ser encontrado [aquí](https://www.youtube.com/watch?v=JyZxQ9mfQzI&t=662s)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBPYc-YI91hZ"
      },
      "source": [
        "## Importamos nuestras librerías\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC0oBzWa-UmM",
        "outputId": "927311f5-4210-491c-c1f0-55897d9e484c"
      },
      "source": [
        "# Primero instalamos tflearn\r\n",
        "\r\n",
        "! pip install tflearn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/3c/0b156d08ef3d4e2a8009ecab2af1ad2e304f6fb99562b6271c68a74a4397/tflearn-0.5.0.tar.gz (107kB)\n",
            "\r\u001b[K     |███                             | 10kB 24.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 20kB 14.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 30kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40kB 11.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 51kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 61kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 71kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 81kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 92kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 102kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (7.0.0)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-cp36-none-any.whl size=127301 sha256=3bb8eb2e99fe666c21d7109fdc35ba10c967beddfe40a553b65107b5b78dd5ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d2/ed/fb9a0d301dd9586c11e9547120278e624227f22fd5f4baf744\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hno1lzKW9IcM",
        "outputId": "be545248-ddb9-4f01-8782-2c46b55ca36e"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import tflearn\r\n",
        "import tflearn.datasets.mnist as mnist\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6Yn3e08U3-h"
      },
      "source": [
        "## Luego importamos nuestros Dados MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVzcqYn298fj",
        "outputId": "4c2d05e0-696e-4384-aac2-9e6569e9cf4c"
      },
      "source": [
        "trainx, trainy, testx, testy = mnist.load_data(one_hot=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading MNIST...\n",
            "Succesfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting mnist/train-images-idx3-ubyte.gz\n",
            "Downloading MNIST...\n",
            "Succesfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading MNIST...\n",
            "Succesfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading MNIST...\n",
            "Succesfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJlqb16UVFUA"
      },
      "source": [
        "## Definimos los parámetros para mi modelo\r\n",
        "\r\n",
        "* Sabemos que ``mnist`` son imagenes de $28$x$28$ ($28$ pixeles de alto y $28$ pixeles de ancho), los vamos a passar  $28$x$28$=$784$ (o sea: $1$ de alto y $784$ de ancho por así decirlo).;\r\n",
        "\r\n",
        "* capa1 y capa2 son las neuronas.\r\n",
        "\r\n",
        "* Nuetras clases son: $0, 1, 2, 3, 4, 5, 6, 7, 8, 9$\r\n",
        "\r\n",
        "* El número de neuronas depende mucho del tipo de problema que vamos atacar (leer más sobre esto). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktz7lkgQ-wYX"
      },
      "source": [
        "entradas = 784\r\n",
        "capa1 = 128\r\n",
        "capa2 = 128\r\n",
        "clases = 10"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWlD4bWZWhWD"
      },
      "source": [
        "## Construimos nuestra Red Neuronal "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz89dldm_B5s"
      },
      "source": [
        "def crear_modelo():\r\n",
        "  tf.compat.v1.reset_default_graph() # para evitar qualquer ruído, etc\r\n",
        "  #tf.reset_default_graph()\r\n",
        "  red = tflearn.input_data([None, entradas]) # \"None\" seria los lotes (Batch_size) veremos más adelante\r\n",
        "  red = tflearn.fully_connected(red, capa1, activation='ReLU')\r\n",
        "  red = tflearn.fully_connected(red, capa2, activation='ReLU')\r\n",
        "  red = tflearn.fully_connected(red, clases, activation='softmax') # 10 neuronas (10 clases)\r\n",
        "  red = tflearn.regression(red, optimizer='sgd', learning_rate=0.01,\r\n",
        "                           loss='categorical_crossentropy')\r\n",
        "  \r\n",
        "  modelo = tflearn.DNN(red) # Deep Neural Network (DNN)\r\n",
        "\r\n",
        "  return modelo\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3l_rAmgX82z"
      },
      "source": [
        "## Luego tendremos nuestro modelo creado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp_NmL9zCRk3",
        "outputId": "2d2f775f-5ad4-4d58-9f16-fba7670150cc"
      },
      "source": [
        "modelo = crear_modelo()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA13RsViUg5P"
      },
      "source": [
        "## Entrenamos nuestro modelo\r\n",
        "\r\n",
        "* ``trainx`` ==> Nuestras características\r\n",
        "\r\n",
        "* ``trainy`` ==> Nuestras clases\r\n",
        "\r\n",
        "* ``validation_set=0.1`` Esto coje $10\\%$ de trainx\r\n",
        "\r\n",
        "* ``show_metric=True`` Para que podamos ver que tan bien está aprendiendo nuestro algortimo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_mQjFnUCVpm",
        "outputId": "411b1238-c710-42ab-ba90-96ab60dc8a8d"
      },
      "source": [
        "modelo.fit(trainx, trainy, validation_set=0.1, show_metric=True, batch_size=500,\r\n",
        "           n_epoch=100)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 9899  | total loss: \u001b[1m\u001b[32m0.28056\u001b[0m\u001b[0m | time: 0.747s\n",
            "| SGD | epoch: 100 | loss: 0.28056 - acc: 0.9159 -- iter: 49000/49500\n",
            "Training Step: 9900  | total loss: \u001b[1m\u001b[32m0.27887\u001b[0m\u001b[0m | time: 1.773s\n",
            "| SGD | epoch: 100 | loss: 0.27887 - acc: 0.9169 | val_loss: 0.27932 - val_acc: 0.9247 -- iter: 49500/49500\n",
            "--\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqEYifvaY4Ww"
      },
      "source": [
        "## Ahora realizamos predicciones\r\n",
        "\r\n",
        "Aquí hacemos predicciones con nuestros datos test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTZ-RFHLNnm-",
        "outputId": "7e784ad9-ed12-40e3-889e-314a8c392dc0"
      },
      "source": [
        "predicciones = np.array(modelo.predict(testx)).argmax(axis=1)\r\n",
        "correctas = testy.argmax(axis=1)\r\n",
        "certeza = np.mean(predicciones == correctas, axis=0)\r\n",
        "\r\n",
        "print(\"La certeza (accuracy) es de: \", certeza)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La certeza (accuracy) es de:  0.9209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkltYGNNZSuZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}